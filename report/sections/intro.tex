\section{Introduction}
    \subsection{What are music genres?}
    \paragraph{}
    Music genres are essential tools for improving our understanding and enjoyment of music. A genre can be a powerful tool when searching for similar music or to highlight innovative musicians. As a tool for understanding and discussing artists' creations, genres are important because they are among the few and most valuable we have available. This way of categorizing sounds is flexible and descriptive, which can dramatically increase our ability to comprehend, recognize, and enjoy music. There are two ways to define a genre: the density of similar characteristics and the sparsity of distinctive features: dense clusters of productions form a music style, whereas pronounced differences define its edges \cite{kosina}. Nevertheless, there are gray areas in the classification of music genres that may cause overlap between categories \cite{iemtronics}. This is true whether reviewing a broad range of genres or an individual artist's discography.
    
    \subsection{Can we detect music genres?}
    \paragraph{}
    In spite of our varying levels of musical knowledge, it is very hard to explicitly define what a music genre a song belongs to just with our human ears \cite{iemtronics}. What makes jazz sound like jazz? And how can you tell the difference between hip hop and the blues? Computers or machines can use machine learning to build interpretive patterns based on data that is fed into them. Based on the data that is fed into the computer, machine learning can automatically create analytical models \cite{adragna_sun}. The power of machine learning principles comes into play when it comes to extracting music signatures from each genre \cite{guo_gu_liu}. We are then able to extract trends and patterns from a large dataset \cite{guo_gu_liu}. A number of techniques have been developed to help classify music genres based on how computers are used as new music equipment is being developed and deployed into our daily lives.
    
    \subsection{How to achieve our goal?}
    \paragraph{}
    Our main goal is to be able to make accurate predictions on a song’s genre. To achieve this, we will explore ways on how neural network architectures and splitting the training and testing data among groups affect our results and see if there are any benefits to do so. Python is used because there exists a collection and code stack of various open-source repositories and it is simple to understand \cite{python}. The Librosa Python module analyzes audio signals and is designed to be used for tracking music signals \cite{librosa}. It includes all of the parts to build a Music information retrieval (MIR) system. This module is very well documented and includes numerous examples and tutorials. Tensorflow is a Python-based scientific computing package. It is an open-source machine learning library used with the keras library designed to handle automatic differentiation libraries, which is helpful for implementing neural networks \cite{tensorflow}.
    
    \subsection{Which dataset will we use?}
    \paragraph{}
    The project’s data uses the GTZAN dataset \cite{kaggle} most frequently for evaluation. This dataset set includes a variety of recording-related sources (personal CDs, radio, microphone recordings), files were collected from 2000-2001. In particular, there are 10 genres, each with 100 audio files, all lasting 30 seconds each \cite{kaggle}. Using this dataset, we extract audio features, namely Mel-frequency Cepstral Coefficients (MFCC), from the raw data using the Librosa library. MFCCs are a small set of features that summarize the spectral envelope (often described in terms of timbre) \cite{haggblade_hong_kao}. They are frequently used in MIR. Since we cannot directly use the audio file as an input for our models, we need to preprocess it and then use the data in the GTZAN dataset. This means extracting useful features from the audio signal. Therefore, MFCC feature extraction is one of the ways to extract useful information from the signal because it defines the brightness of a sound \cite{haggblade_hong_kao}. It can also be used to calculate the timbre (quality) of the sound \cite{ceylan_hardala_kara_hardalac}. Then, a training set with category labels is provided for the purpose of training and evaluating the performances of the classifiers. A test set with no category labels is given to test the trained classifiers against unseen data.
 
    Everything will be and can be run from a Jupyter notebook. The initial step is to import all libraries needed for our project, regarding music genre classification. From the GTZAN dataset, we are able to load all songs in it. Once the dataset is loaded and saved via the dataset path, save\_mfcc is defined to perform the MFCCs extraction and save them into a .json file along with their respective genres. We divided each sample songs into different segments of 30 seconds and create our MFCCs. This ensures we have even more data to play around with. Once the data is ready and has been preprocessed, we can create both of our models for music genre classification.\\
    
    \subsection{Which models best suit our case?}
        \paragraph{}
        Convolution neural network is based on visual images. Its algorithms predict future datasets based on how they process and interpret visual images. CNN image classifications take an input image, process it and classify it under certain categories \cite{cnn_rnn}. Computers see an input image as an array of pixels and it depends on the image resolution. By analyzing images and recognizing information in images, machines can successfully analyze and classify future data \cite{cnn_rnn_2}. A CNN can classify music genres through the study of spectrograms (visual graphs of musical frequencies) which, in turn, enables machines to identify the category of particular types of music \cite{cnn_rnn}. Each input image passes through a series of convolution layers with kernels, pooling, fully connected layers and applies a softmax function to classify an object with probabilistic values between 0 and 1. 

        \paragraph{}
        Recurrent neural network learns how to remember sequences of information. Their unique characteristic is their memory, which draws on information from past inputs to influence current inputs and outputs \cite{cnn_rnn}. A pattern usually emerges when dealing with audio information from songs. These deep learning algorithms are commonly used for ordinal or temporal problems \cite{cnn_rnn_2}. As far as the RNN is concerned, it is a little different from traditional neural networks. It stores and uses the past data as information to predict future outcomes \cite{cnn_rnn}. The output from recurrent neural networks depends on the previous elements within the sequence, unlike traditional deep learning models which assume inputs and outputs are independent.